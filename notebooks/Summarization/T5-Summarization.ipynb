{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T5-Summarization.ipynb","provenance":[{"file_id":"1Y2p7Anh4_u6zUUUcZF365no0ESoDM0Yv","timestamp":1590208777670}],"collapsed_sections":[],"authorship_tag":"ABX9TyM0FITIZNxgRhU0iUA9Fg3v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c950e7aa8e69448ca87ca9d23cc9208e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_429a83bcefaf495283cce3b997e94fc4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_19f629b197f944b1908e185e691f61ca","IPY_MODEL_35739344e5904d0ba087e472339bb2b6"]}},"429a83bcefaf495283cce3b997e94fc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19f629b197f944b1908e185e691f61ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b710c2f45254402b851b20096133e51b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1200,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1200,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff2128b3aad24750a5b7134a1d5de2ec"}},"35739344e5904d0ba087e472339bb2b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_28c6d605026443f0acfc6d73357a75f7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.20k/1.20k [00:00&lt;00:00, 8.29kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c1c7b6c57b3242d4ac77f0f92f2217fa"}},"b710c2f45254402b851b20096133e51b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ff2128b3aad24750a5b7134a1d5de2ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28c6d605026443f0acfc6d73357a75f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c1c7b6c57b3242d4ac77f0f92f2217fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01fb4d4154104fca8f3c1e1268b4bb1e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3392c0d914d7452cba6fd09523378e80","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7dc02b78b0744bbeacfdedfefc99e02f","IPY_MODEL_8fefe292f56148029b8e6abf887cf154"]}},"3392c0d914d7452cba6fd09523378e80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7dc02b78b0744bbeacfdedfefc99e02f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_53cd3a9f00db4dc19a5dfdef787f669d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2950825948,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2950825948,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cc8372f2aa624787b8b6f6331c5bbccb"}},"8fefe292f56148029b8e6abf887cf154":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c78ddea1f34e446ca2e468526e96552e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.95G/2.95G [00:53&lt;00:00, 55.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13a747e67172493aa97bdf16e7f0ab0f"}},"53cd3a9f00db4dc19a5dfdef787f669d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cc8372f2aa624787b8b6f6331c5bbccb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c78ddea1f34e446ca2e468526e96552e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"13a747e67172493aa97bdf16e7f0ab0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff8f27f325784fccae74d2bc2a7f4137":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_996ce33b241140629b030a22ee5d9e77","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_45f19e3db3d54aa989cc22f5c114f91a","IPY_MODEL_eb635c2044e9446d9ae543e5b3ccf311"]}},"996ce33b241140629b030a22ee5d9e77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45f19e3db3d54aa989cc22f5c114f91a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6e1e06bb6edd463590692c191a04094a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":791656,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":791656,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8cd61b4f747244a58b3cfaa64d824105"}},"eb635c2044e9446d9ae543e5b3ccf311":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8d52cb119936481aafc947f2637d8957","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 792k/792k [00:20&lt;00:00, 38.0kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_56862ed178474263a666f476bfe1d7fe"}},"6e1e06bb6edd463590692c191a04094a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8cd61b4f747244a58b3cfaa64d824105":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d52cb119936481aafc947f2637d8957":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"56862ed178474263a666f476bfe1d7fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"FqVAUC8Lvf--","colab_type":"code","outputId":"a3d5521c-f81b-4305-aca7-45af1ed5cec8","executionInfo":{"status":"ok","timestamp":1590472116537,"user_tz":420,"elapsed":8120,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":581}},"source":["!pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n","\u001b[K     |████████████████████████████████| 665kB 9.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 11.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 43.2MB/s \n","\u001b[?25hCollecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 59.0MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=18df090d4408b41940ff90a588850513b474e86b3f50824cd428b674cb686428\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z6tdzi8riG6v","colab_type":"code","colab":{}},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qnIiqE9PBgA5","colab_type":"code","outputId":"4fbd8995-9504-485e-de69-aa1810ae3835","executionInfo":{"status":"ok","timestamp":1590472720347,"user_tz":420,"elapsed":611921,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","root_path = 'gdrive/Shared drives/CS263/data/american_rhetoric/'\n","import os\n","os.chdir(root_path + 'speech_bank')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c4hx6SocCSTc","colab_type":"code","outputId":"9f274eb9-a581-4be0-a4e5-48d90e1e4a6e","executionInfo":{"status":"ok","timestamp":1590472721935,"user_tz":420,"elapsed":1157,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["retval = os.getcwd()\n","print(\"Current working directory %s\" % retval)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Current working directory /content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IdsFr3l8wa-b","colab_type":"code","colab":{}},"source":["import torch\n","\n","from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dVEtoMX9w_Ju","colab_type":"code","outputId":"605db2ae-f516-470b-bbb0-8132e859105b","executionInfo":{"status":"ok","timestamp":1590472735408,"user_tz":420,"elapsed":9114,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["import pandas as pd\n","\n","import numpy as np\n","# !gdown --id 12_VY9LDKd6WBKzNnE_oNsSrjMUR_BTrO\n","# df = pd.read_csv('parsed-with_summaries_wordfrequency.csv')\n","\n","!gdown --id 1J7h0H8HsqqcLlbM0zUZGGCn2jh3ZnpgD\n","df = pd.read_csv('parsed.csv')\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1J7h0H8HsqqcLlbM0zUZGGCn2jh3ZnpgD\n","To: /content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/parsed.csv\n","16.6MB [00:00, 52.9MB/s]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>speaker</th>\n","      <th>transcript</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Congressional Gold Medal Acceptance Address</td>\n","      <td>Aung San Suu Kyi</td>\n","      <td>This is one of the most moving days of my life...</td>\n","      <td>2012</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Memorial Remarks for Ronald Reagan</td>\n","      <td>Prime Minister Brian Mulroney</td>\n","      <td>In the spring of 1987, President Reagan and I ...</td>\n","      <td>2004</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Address to the American Society of Newspaper E...</td>\n","      <td>Dwight D. Eisenhower</td>\n","      <td>President Bryan, distinguished guests of this ...</td>\n","      <td>1953</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2004 Democratic National Convention Address</td>\n","      <td>Al Gore</td>\n","      <td>Thank you, very much. Thank you. Thank you, ve...</td>\n","      <td>2004</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Speech to the D.C. Federalist Society Lawyers ...</td>\n","      <td>Edwin Meese III</td>\n","      <td>A large part of American history has been the ...</td>\n","      <td>1985</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               title  ...  year\n","0        Congressional Gold Medal Acceptance Address  ...  2012\n","1                 Memorial Remarks for Ronald Reagan  ...  2004\n","2  Address to the American Society of Newspaper E...  ...  1953\n","3        2004 Democratic National Convention Address  ...  2004\n","4  Speech to the D.C. Federalist Society Lawyers ...  ...  1985\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"ZAghtR-zCsKd","colab_type":"code","outputId":"6b122b57-38eb-4f4f-abba-6e2a17a1025b","executionInfo":{"status":"ok","timestamp":1590472735409,"user_tz":420,"elapsed":5727,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.info()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1202 entries, 0 to 1201\n","Data columns (total 4 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   title       1202 non-null   object\n"," 1   speaker     1202 non-null   object\n"," 2   transcript  1202 non-null   object\n"," 3   year        1202 non-null   int64 \n","dtypes: int64(1), object(3)\n","memory usage: 37.7+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6C9HUibTyiVs","colab_type":"code","outputId":"930d8eb5-000d-4035-8afd-9da6b5fd72fb","executionInfo":{"status":"ok","timestamp":1590472808508,"user_tz":420,"elapsed":77419,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["c950e7aa8e69448ca87ca9d23cc9208e","429a83bcefaf495283cce3b997e94fc4","19f629b197f944b1908e185e691f61ca","35739344e5904d0ba087e472339bb2b6","b710c2f45254402b851b20096133e51b","ff2128b3aad24750a5b7134a1d5de2ec","28c6d605026443f0acfc6d73357a75f7","c1c7b6c57b3242d4ac77f0f92f2217fa","01fb4d4154104fca8f3c1e1268b4bb1e","3392c0d914d7452cba6fd09523378e80","7dc02b78b0744bbeacfdedfefc99e02f","8fefe292f56148029b8e6abf887cf154","53cd3a9f00db4dc19a5dfdef787f669d","cc8372f2aa624787b8b6f6331c5bbccb","c78ddea1f34e446ca2e468526e96552e","13a747e67172493aa97bdf16e7f0ab0f","ff8f27f325784fccae74d2bc2a7f4137","996ce33b241140629b030a22ee5d9e77","45f19e3db3d54aa989cc22f5c114f91a","eb635c2044e9446d9ae543e5b3ccf311","6e1e06bb6edd463590692c191a04094a","8cd61b4f747244a58b3cfaa64d824105","8d52cb119936481aafc947f2637d8957","56862ed178474263a666f476bfe1d7fe"]}},"source":["T5_PATH = 't5-large'\n","\n","t5_model = T5ForConditionalGeneration.from_pretrained(T5_PATH)\n","t5_tokenizer = T5Tokenizer.from_pretrained(T5_PATH)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c950e7aa8e69448ca87ca9d23cc9208e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1200.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01fb4d4154104fca8f3c1e1268b4bb1e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2950825948.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff8f27f325784fccae74d2bc2a7f4137","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7QtqXQeCqXT-","colab_type":"code","outputId":"17aab6a6-4a0d-4df6-aeb5-ab81a0e8936a","executionInfo":{"status":"ok","timestamp":1590472827821,"user_tz":420,"elapsed":94580,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["t5_model.to(device)\n","t5_model.eval()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 1024)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 1024)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","              (relative_attention_bias): Embedding(32, 16)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (12): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (13): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (14): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (15): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (16): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (17): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (18): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (19): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (20): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (21): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (22): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (23): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 1024)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","              (relative_attention_bias): Embedding(32, 16)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","              (relative_attention_bias): Embedding(32, 16)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (12): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (13): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (14): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (15): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (16): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (17): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (18): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (19): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (20): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (21): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (22): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (23): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1024, out_features=1024, bias=False)\n","              (k): Linear(in_features=1024, out_features=1024, bias=False)\n","              (v): Linear(in_features=1024, out_features=1024, bias=False)\n","              (o): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"uWJeHCcHIPew","colab_type":"code","colab":{}},"source":["def t5_summarize(i, input_text, num_beams=4, num_words=200):\n","    preprocess_text = input_text.strip().replace(\"\\n\",\" \")\n","    input_text = \"summarize: \" + preprocess_text\n","    input_tokenized = t5_tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1024).to(device)\n","    # summary_task = torch.tensor([[21603, 10]]).to(device)\n","    # input_tokenized = torch.cat([summary_task, input_tokenized], dim=-1).to(device)\n","    summary_ids = t5_model.generate(input_tokenized,\n","                                    num_beams=int(num_beams),\n","                                    no_repeat_ngram_size=3,\n","                                    length_penalty=2.0,\n","                                    min_length=30,\n","                                    max_length=int(num_words),\n","                                    early_stopping=True)\n","    #output = [t5_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n","    output = [t5_tokenizer.decode(g, skip_special_tokens=True) for g in summary_ids]\n","    print('\\n\\n', i, 'text:', input_text, '\\n Summarized:', output)\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7zQ4reSALgp","colab_type":"code","outputId":"96bfbd77-e07b-4122-ce97-81c75a8d2ec5","executionInfo":{"status":"ok","timestamp":1590472834670,"user_tz":420,"elapsed":90961,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["summarized  = t5_summarize(1, df['transcript'][1])\n","print(summarized)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","\n"," 1 text: summarize: In the spring of 1987, President Reagan and I were driven into a large hangar at the Ottawa Airport, to await the arrival of Mrs. Reagan and my wife, Mila, prior to departure ceremonies for their return to Washington. We were alone except for the security details.President Reagan's visit had been important, demanding, and successful. Our discussions reflected the international agenda of the times: the nuclear threat posed by the Soviet Union and the missile deployment by NATO; pressures in the Warsaw pact; challenges resulting from the Berlin Wall and the ongoing separation of Germany; and bilateral and hemispheric free trade.President Reagan had spoken to Parliament, handled complex files with skill and good humor, strongly impressing his Canadian hosts. And here we were waiting for our wives.When their car drove in a moment later, out stepped Nancy and Mila looking like a million bucks. And as they headed towards us, President Reagan beamed, he threw his arm around my shoulder, and he said with a grin: \"You know, Brian, for two Irishmen we sure married up.\"In that visit -- in that moment -- one saw the quintessential Ronald Reagan -- the leader we respected, the neighbor we admired, and the friend we loved -- a President of the United States of America whose truly remarkable life we celebrate in this magnificent cathedral today.Presidents and Prime Ministers everywhere, I suspect, sometimes wonder how history will deal with them. Some even evince a touch of the insecurity of Thomas d'Arcy McGee, an Irish immigrant to Canada, who became a Father of our Confederation. In one of his poems, McGee, thinking of his birthplace, wrote poignantly:Am I remembered in Erin?I charge you, speak me trueHas my name a sound, a meaningIn the scenes my boyhood knew.Ronald Reagan will not have to worry about Erin because they remember him well and affectionately there. Indeed they do: from Erin to Estonia, from Maryland to Madagascar, from Montreal to Monterey. Ronald Reagan does not enter history tentatively -- he does so with certainty and panache. At home and on the world stage, his were not the pallid etchings of a timorous politician. They were the bold strokes of a confident and accomplished leader.Some in the West, during the early 1980s, believed communism and democracy were equally valid and viable. This was the school of \"moral equivalence.\" In contrast Ronald Reagan saw Soviet communism as a menace to be confronted in the genuine belief that its squalid underpinnings would fall swiftly to the gathering winds of freedom -- provided, as he said, that NATO and the industrialized democracies stood firm and united. They did. And we know now who was right.Ronald Reagan was a President who inspired his nation and transformed the world. He possessed a rare and prized gift called leadership -- that ineffable and magical quality that sets some men and women apart so that millions will follow them as they conjure up grand visions and invite their countrymen to dream big and exciting dreams. I always thought that President Reagan's understanding of the nobility of the Presidency coincided with that American dream.One day in Brussels President Mitterrand in referring to President Reagan said: \"Il a vraiment la notion de l'Etat.\" Rough translation: \"He really has a sense of the State about him.\" The translation does not fully capture the profundity of the observation. What President Mitterrand meant is that there is a vast difference between the job of President and the role of President.Ronald Reagan fulfilled both with elegance and ease, embodying himself that unusual alchemy of history and tradition and achievement, and inspirational conduct and national pride that define the special role the President of the United States of America must assume at all times at home and around the world. \"La notion de l'Etat\" -- no one understood it better than Ronald Reagan and no one could more eloquently summon his nation to high purpose or bring forth the majesty of the Presidency and made it glow better than the man who referred to his own nation as a \"[shining] city on a hill\"May our common future and that of our great nations be guided by wise men and women who will remember always the golden achievements of the Reagan era and the success that can be theirs if the values of freedom and democracy are preserved unsullied and undiminished, until the unfolding decades can remember little else.I have been truly blessed to have been a friend of Ronald Reagan. I am grateful that our paths crossed and that our lives touched. I shall always remember him with the deepest admiration and affection. And I will always feel honored by the journey that we traveled together in search of better and more peaceful tomorrows for all God's children, everywhere.And so, in the presence of his beloved and indispensable Nancy, his children, his family and his friends, and all of the American people that he so deeply revered, I say au revoir today to a gifted leader, an historic President, and a gracious human being. And I do so with a line from Yeats, who wrote: \n"," Summarized: [\"bob greene: Ronald Reagan was a president who inspired his nation and transformed the world. greene says he embodied the unusual alchemy of history, tradition, achievement. he says Reagan's vision of a united u.s. was based on a sense of the nation's majesty.\"]\n","[\"bob greene: Ronald Reagan was a president who inspired his nation and transformed the world. greene says he embodied the unusual alchemy of history, tradition, achievement. he says Reagan's vision of a united u.s. was based on a sense of the nation's majesty.\"]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JHnq7mjAAeo0","colab_type":"code","outputId":"8dc5f6e0-f296-4393-86b9-19870b2e953e","executionInfo":{"status":"ok","timestamp":1590472834671,"user_tz":420,"elapsed":41695,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["summarized = ''.join(summarized)\n","print(len(summarized.split()))\n","index = summarized.rfind(\".\")\n","print(summarized[:index + 1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["43\n","bob greene: Ronald Reagan was a president who inspired his nation and transformed the world. greene says he embodied the unusual alchemy of history, tradition, achievement. he says Reagan's vision of a united u.s. was based on a sense of the nation's majesty.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rlMif6Hsyy2_","colab_type":"code","outputId":"f3e5c8ae-ea06-4272-d674-8203c1120fc2","executionInfo":{"status":"ok","timestamp":1590481200680,"user_tz":420,"elapsed":8404023,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1G-0N_afrW-KudiSmOCoVhrzqyj9Dota9"}},"source":["for i, text in enumerate(df.transcript):\n","  summarized = t5_summarize(i, df['transcript'][i])\n","  # convert list to string\n","  summarized = ''.join(summarized)\n","  # find the index of the last occurrence of period. Delete incomplete sentence.\n","  index1 = summarized.rfind(\".\")\n","  index2 = summarized.rfind(\"?\")\n","  index3 = summarized.rfind('!')\n","  index = max(index1, index2, index3)\n","\n","  # removed unfinished sentence in the summary\n","  df.loc[df.index[i],'summary'] = summarized[:index+1]\n","\n","  print('\\n Number of words in T5 summarized text:', len(summarized.split()), '\\n in processed summary', len(df.loc[df.index[i],'summary'].split()))\n","  print('\\n Processed Summary', df.loc[df.index[i],'summary'])\n","\n","  if i%200 == 0:\n","    df.to_csv('parsed-with_summaries_t5_11b_200words_raw.csv', index = False)\n","\n","# print('\\n Before removing invalid summaries:', df.info())\n","# Uncomment to update the parsed-with_summaries data.\n","# max_length = 200\n","df.to_csv('parsed-with_summaries_t5_11b_200words_raw.csv', index = False)\n","\n","df.summary.replace('', np.nan, inplace = True)\n","# Remove rows with summary NaN\n","\n","df = df.dropna(subset =['summary']).reset_index(drop = True)\n","\n","print('After removing invalid summaries:', df.info())\n","df.to_csv('parsed-with_summaries_t5_11b_200words.csv', index = False)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"tfCwv0Uz_ROh","colab_type":"code","colab":{}},"source":["df.to_csv('parsed-with_summaries_t5_large_raw.csv', index = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ONHij3PfBJW4","colab_type":"code","outputId":"59e06f31-11a0-4fa4-eff9-9f259c395a63","executionInfo":{"status":"ok","timestamp":1590481270102,"user_tz":420,"elapsed":857,"user":{"displayName":"Maggie Xiao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaIrgO-bl1lSloX2VjiMQa0dRQNrF8zO6h2upa8Ss=s64","userId":"09214204599774109902"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>speaker</th>\n","      <th>transcript</th>\n","      <th>year</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Congressional Gold Medal Acceptance Address</td>\n","      <td>Aung San Suu Kyi</td>\n","      <td>This is one of the most moving days of my life...</td>\n","      <td>2012</td>\n","      <td>\"this is a moment for which i have been waitin...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Memorial Remarks for Ronald Reagan</td>\n","      <td>Prime Minister Brian Mulroney</td>\n","      <td>In the spring of 1987, President Reagan and I ...</td>\n","      <td>2004</td>\n","      <td>bob greene: Ronald Reagan was a president who ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Address to the American Society of Newspaper E...</td>\n","      <td>Dwight D. Eisenhower</td>\n","      <td>President Bryan, distinguished guests of this ...</td>\n","      <td>1953</td>\n","      <td>president george w. bush makes his first forma...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2004 Democratic National Convention Address</td>\n","      <td>Al Gore</td>\n","      <td>Thank you, very much. Thank you. Thank you, ve...</td>\n","      <td>2004</td>\n","      <td>gloria borger: i didn't run for re-election, b...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Speech to the D.C. Federalist Society Lawyers ...</td>\n","      <td>Edwin Meese III</td>\n","      <td>A large part of American history has been the ...</td>\n","      <td>1985</td>\n","      <td>ruben navarrette: as we approach the bicentenn...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               title  ...                                            summary\n","0        Congressional Gold Medal Acceptance Address  ...  \"this is a moment for which i have been waitin...\n","1                 Memorial Remarks for Ronald Reagan  ...  bob greene: Ronald Reagan was a president who ...\n","2  Address to the American Society of Newspaper E...  ...  president george w. bush makes his first forma...\n","3        2004 Democratic National Convention Address  ...  gloria borger: i didn't run for re-election, b...\n","4  Speech to the D.C. Federalist Society Lawyers ...  ...  ruben navarrette: as we approach the bicentenn...\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"VRWKj6jGEf9Z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3D8YbcUrAoMT","colab_type":"text"},"source":["**50 max**\n"," summarized: ['this is a moment for which I have been waiting for many years. many of you have done so much to uphold our cause that it would take me more than one afternoon to recite all the names of those whom I hold']\n","\n"," **120 max**\n","summarized:   summarized: ['this is a moment for which I have been waiting for many years. many of you have done so much to uphold our cause that it would take me more than one afternoon to recite all the names of those whom I hold dear in appreciation and gratitude. this task has been made possible by the reform measures instituted by president U Thein Sein.']\n"]}]}