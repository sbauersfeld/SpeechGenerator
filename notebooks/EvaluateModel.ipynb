{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EvaluateModel.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Px8Z3Vs70IES","colab_type":"text"},"source":["# General Imports and Utilities"]},{"cell_type":"code","metadata":{"id":"4pISFAs00FMg","colab_type":"code","colab":{}},"source":["import os\n","\n","def quote(t):\n","    return '\"{}\"'.format(t)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6qFj5Gc52pq","colab_type":"text"},"source":["# Model Evaluation\n","\n","This notebook computes perplexity and performs text generation to evaluate our models."]},{"cell_type":"code","metadata":{"id":"ff6YyCwb7Pmt","colab_type":"code","colab":{}},"source":["# MODEL_TYPE=\"gpt2\" # The type of model we are using\n","# CHECKPOINT=\"/content/gdrive/Shared drives/CS263/models/pres_speeches/\" # location of saved weights\n","# CHECKPOINT_PATH='\"/content/gdrive/Shared drives/CS263/models/pres_speeches/\"' # same as above but with double quotes for bash\n","\n","# TRAIN_DATA=\"/content/gdrive/Shared drives/CS263/data/pres_speeches/pres_speech_train.txt\"\n","# EVAL_DATA=\"/content/gdrive/Shared drives/CS263/data/pres_speeches/pres_speech_val.txt\"\n","# TEST_DATA=\"/content/gdrive/Shared drives/CS263/data/pres_speeches/pres_speech_test.txt\"\n","\n","# TRAIN_DATA_PATH='\"/content/gdrive/Shared drives/CS263/data/pres_speeches/pres_speech_train.txt\"'\n","# EVAL_DATA_PATH='\"/content/gdrive/Shared drives/CS263/data/pres_speeches/pres_speech_val.txt\"'\n","# TEST_DATA_PATH='\"/content/gdrive/Shared drives/CS263/data/pres_speeches/pres_speech_test.txt\"'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TEc_DZc5_Dlp","colab_type":"code","colab":{}},"source":["GDRIVE_MOUNT_PATH = '/content/gdrive'\n","NLP_DRIVE_PATH = os.path.join(GDRIVE_MOUNT_PATH, 'Shared drives/CS263')\n","\n","# EXP_PARENT_DIR points to the directory where all experiments are stored. Can be updated.\n","EXP_PARENT_DIR = os.path.join(NLP_DRIVE_PATH, \"models/american_rhetoric\")\n","EXP_NAME = \"tones_watson-summarized_bart_large_xsm/converted-summary_tone\" # TODO: change this as necessary before each experiment\n","EXP_DIR = os.path.join(EXP_PARENT_DIR, EXP_NAME) # Points to the current experiment dir\n","\n","# Update this to point to your desired dataset\n","DATASET_DIR = os.path.join(NLP_DRIVE_PATH, 'data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone')\n","\n","OUTPUT_DIR = quote(os.path.join(EXP_DIR, 'eval_output'))\n","OUTPUT_DIR_TRAIN = quote(os.path.join(EXP_DIR, 'output_train'))\n","OUTPUT_DIR_VAL = quote(os.path.join(EXP_DIR, 'output_val'))\n","OUTPUT_DIR_TEST = quote(os.path.join(EXP_DIR, 'output_test'))\n","\n","# TRAIN_DATA = os.path.join(DATASET_DIR, 'parsed-summarized-converted-train.txt')\n","# EVAL_DATA = os.path.join(DATASET_DIR, 'parsed-summarized-converted-val.txt')\n","# TEST_DATA = os.path.join(DATASET_DIR, 'parsed-summarized-converted-test.txt')\n","TRAIN_DATA = os.path.join(DATASET_DIR, 'data-train.txt')\n","EVAL_DATA = os.path.join(DATASET_DIR, 'data-val.txt')\n","TEST_DATA = os.path.join(DATASET_DIR, 'data-test.txt')\n","\n","TRAIN_DATA_PATH=quote(TRAIN_DATA)\n","EVAL_DATA_PATH=quote(EVAL_DATA)\n","TEST_DATA_PATH=quote(TEST_DATA)\n","\n","MODEL_TYPE=\"gpt2-medium\" # The type of model we are using\n","CHECKPOINT=os.path.join(NLP_DRIVE_PATH, \"models/american_rhetoric/tones_watson-summarized_bart_large_xsm/converted-summary_tone/output\") # location of saved weights\n","CHECKPOINT_PATH=quote(CHECKPOINT) # same as above but with double quotes for bash"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wv01dnTABlMK","colab_type":"code","outputId":"acb22366-9594-420e-8ddc-0b72dc82f05b","executionInfo":{"status":"ok","timestamp":1590694801793,"user_tz":420,"elapsed":804,"user":{"displayName":"Scott Bauersfeld","photoUrl":"","userId":"03921899941820663153"}},"colab":{"base_uri":"https://localhost:8080/","height":367}},"source":["print(GDRIVE_MOUNT_PATH)\n","print(NLP_DRIVE_PATH)\n","print(EXP_PARENT_DIR)\n","print(EXP_NAME)\n","print(EXP_DIR)\n","print(DATASET_DIR)\n","\n","print(OUTPUT_DIR)\n","print(OUTPUT_DIR_TRAIN)\n","print(OUTPUT_DIR_TEST)\n","print(OUTPUT_DIR_VAL)\n","\n","\n","print(TRAIN_DATA)\n","print(EVAL_DATA)\n","print(TEST_DATA)\n","\n","print(TRAIN_DATA_PATH)\n","print(EVAL_DATA_PATH)\n","print(TEST_DATA_PATH)\n","\n","print(MODEL_TYPE)\n","print(CHECKPOINT)\n","print(CHECKPOINT_PATH)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive\n","/content/gdrive/Shared drives/CS263\n","/content/gdrive/Shared drives/CS263/models/american_rhetoric\n","tones_watson-summarized_bart_large_xsm/converted-summary_tone\n","/content/gdrive/Shared drives/CS263/models/american_rhetoric/tones_watson-summarized_bart_large_xsm/converted-summary_tone\n","/content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone\n","\"/content/gdrive/Shared drives/CS263/models/american_rhetoric/tones_watson-summarized_bart_large_xsm/converted-summary_tone/eval_output\"\n","\"/content/gdrive/Shared drives/CS263/models/american_rhetoric/tones_watson-summarized_bart_large_xsm/converted-summary_tone/output_train\"\n","\"/content/gdrive/Shared drives/CS263/models/american_rhetoric/tones_watson-summarized_bart_large_xsm/converted-summary_tone/output_test\"\n","\"/content/gdrive/Shared drives/CS263/models/american_rhetoric/tones_watson-summarized_bart_large_xsm/converted-summary_tone/output_val\"\n","/content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone/data-train.txt\n","/content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone/data-val.txt\n","/content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone/data-test.txt\n","\"/content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone/data-train.txt\"\n","\"/content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone/data-val.txt\"\n","\"/content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone/data-test.txt\"\n","gpt2-medium\n","/content/gdrive/Shared drives/CS263/models/american_rhetoric/tones_watson-summarized_bart_large_xsm/converted-summary_tone/output\n","\"/content/gdrive/Shared drives/CS263/models/american_rhetoric/tones_watson-summarized_bart_large_xsm/converted-summary_tone/output\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JwgfFTcP7CXu","colab_type":"text"},"source":["# Setup\n","\n","We still need the hugging face transformers library. Clone it here and install dependencies."]},{"cell_type":"code","metadata":{"id":"ddsrax0_5076","colab_type":"code","colab":{}},"source":["# remove the capture to show output from this cell\n","%%capture\n","\n","import os\n","\n","# remove previous installations and clone the repo\n","!rm -rm /content/transformers\n","!git clone https://github.com/huggingface/transformers\n","\n","# make sure all dependencies are installed\n","os.chdir('/content/transformers')\n","\n","!pip install .\n","!pip install -r ./examples/requirements.txt\n","\n","# navigate to folder with the language modeling training script\n","os.chdir('/content/transformers/examples/language-modeling')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bz88JKXo698g","colab_type":"code","outputId":"2d7fc3c4-2665-4d8a-f809-dd238ccc3a6e","executionInfo":{"status":"ok","timestamp":1590949699181,"user_tz":420,"elapsed":22886,"user":{"displayName":"Scott Bauersfeld","photoUrl":"","userId":"03921899941820663153"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["# connect to google drive so we can access our data set\n","from google.colab import drive\n","drive.mount(GDRIVE_MOUNT_PATH)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZetWHfRk9B_j","colab_type":"text"},"source":["# Generate Text\n","\n","The next two blocks generate text based on the input prompt."]},{"cell_type":"code","metadata":{"id":"VsJcjcSM5mkC","colab_type":"code","outputId":"da902788-24ba-4abe-ec90-127fc5553740","executionInfo":{"status":"ok","timestamp":1590694952454,"user_tz":420,"elapsed":32033,"user":{"displayName":"Scott Bauersfeld","photoUrl":"","userId":"03921899941820663153"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# comment the line below to show output from this cell\n","# %%capture\n","\n","# this cell just loads our pretrained model\n","from transformers import AutoConfig\n","from transformers import AutoTokenizer\n","from transformers import AutoModelWithLMHead\n","import torch\n","\n","config = AutoConfig.from_pretrained(CHECKPOINT)\n","tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n","\n","model = AutoModelWithLMHead.from_pretrained(CHECKPOINT, config=config)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 1024)\n","    (wpe): Embedding(1024, 1024)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (12): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (13): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (14): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (15): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (16): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (17): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (18): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (19): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (20): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (21): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (22): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (23): Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"6ztggJNt6xYL","colab_type":"code","outputId":"59d801b5-ed4b-43db-b08c-d6253d17da3d","executionInfo":{"status":"ok","timestamp":1590634778803,"user_tz":420,"elapsed":18583,"user":{"displayName":"Scott Bauersfeld","photoUrl":"","userId":"03921899941820663153"}},"colab":{"base_uri":"https://localhost:8080/","height":783}},"source":["# change this prompt to get different speeches\n","# PROMPT = '<title=\\\"Government Response to the COVID-19 Pandemic\\\">\\n<president=\\\"kennedy\\\">\\n<date=\\\"April 10, 1929\\\">'\n","PROMPT = \"\"\"\n","<title=\"Government Response to the COVID-19 Pandemic\">\n","<speaker=\"Barack Obama\">\n","<year=\"1990\">\n","<summary=\"Hopsitals will need more personal protective equipment. The stock market is volatile. Everyone should adhere to social distancing and general hygiene to stay healthy.\">\n","\"\"\"\n","print(PROMPT)\n","\n","MAX_LENGTH=512\n","TOP_K=50\n","TOP_P=0.95\n","NUM_OUTPUTS=3\n","\n","input_ids = tokenizer.encode(PROMPT, return_tensors=\"pt\").to(device)\n","\n","sample_outputs = model.generate(\n","    input_ids,\n","    do_sample=True, \n","    max_length=MAX_LENGTH, \n","    top_k=TOP_K, \n","    top_p=TOP_P, \n","    num_return_sequences=NUM_OUTPUTS,\n","    repetition_penalty=None,\n","    early_stopping=True\n",")\n","\n","output_txt = \"\"\n","print(\"Output:\\n\" + 50 * '-')\n","for i, sample_output in enumerate(sample_outputs):\n","  output_txt += \"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True))\n","\n","print(output_txt)\n","\n","with open(os.path.join(EXP_DIR, \"sample_generation.txt\"), \"w\") as fp:\n","  fp.writelines(output_txt)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"],"name":"stderr"},{"output_type":"stream","text":["\n","<title=\"Government Response to the COVID-19 Pandemic\">\n","<speaker=\"Barack Obama\">\n","<year=\"1990\">\n","<summary=\"Hopsitals will need more personal protective equipment. The stock market is volatile. Everyone should adhere to social distancing and general hygiene to stay healthy.\">\n","\n","Output:\n","--------------------------------------------------\n","0: \n","<title=\"Government Response to the COVID-19 Pandemic\">\n","<speaker=\"Barack Obama\">\n","<year=\"1990\">\n","<summary=\"Hopsitals will need more personal protective equipment. The stock market is volatile. Everyone should adhere to social distancing and general hygiene to stay healthy.\">\n","<tone=\"analytical, joy\">\n","Good afternoon.\n","So, last weekend, we got a couple of cases of the coronavirus -- the coronavirus -- from China. They're the largest number that we've seen in history.\n","So we're going to be sending hundreds of thousands of samples in order to find out who did this. And it's likely that somebody had contaminated somewhere, and had come into contact with infected individuals overseas in a number of countries. That's a concern. But as with any virus, the main question is: Do we have the right people in this country to take these samples? And we have the right people in the CDC and our Health and Human Services departments, who are in this country doing everything in their power to try and get these samples and get all the information they can before people get sick. And that will be a key aspect of the response.\n","So I'd like to speak to you about a variety of things that we're doing. We're trying to find out, how can we put more people and more services in place in order to try to fight the spread of the virus? And so this week, I’m going to do the following.\n","First, I’m going to address specific cases.\n","Number one, there was one person who had traveled to China.\n","We will not let that individual get into the United States; we will not allow that to happen.\n","It’s important for us to know exactly what they did and for us to know that they were traveling that weekend.\n","That person was going to New York City. It’s critical we know precisely where they went.\n","And obviously we will be doing more, in parallel to that case, but it is important for us to know who they are because there is an extraordinary number of people out there who are infected.\n","The other thing that we’re doing is we will be sending to our health departments additional personal protective equipment.\n","And we’ve already done it here. I’m going to be doing that in addition to the personal protective equipment that we send out to hospitals, CDC. I think that1: \n","<title=\"Government Response to the COVID-19 Pandemic\">\n","<speaker=\"Barack Obama\">\n","<year=\"1990\">\n","<summary=\"Hopsitals will need more personal protective equipment. The stock market is volatile. Everyone should adhere to social distancing and general hygiene to stay healthy.\">\n","<tone=\"analytical, joy\">\n","Thank you, Mr. Chairman. Thank you, Mr. Chairman. I'm afraid the -- the response of health and other facilities to the COVID-19 virus could take a little longer than we needed it to. I would like to share the specifics of our response so you don't have to wait. First, we're deploying 100,000 of our own people, including our first responders and our military and healthcare professionals, to support local, state, and federal health and disaster operations in the states from Massachusetts to California, New York to Florida, New Jersey, Connecticut, Texas, Pennsylvania, Pennsylvania, Florida, Ohio, North Carolina, New Jersey, Virginia, Maryland, New Hampshire, and Maine. We are deploying additional responders as additional facilities are needed. These additional resources will help us do more in response to the COVID-19 virus. It’s a tremendous undertaking. And, as with any response, we will meet this challenge with care and resolve.\n","We have an entire range of supplies and protective gear at our disposal that will provide protection in the event of a pandemic. The first responders will be working with state and local health departments as necessary. You don't need to apply the uniformed services and public health advice. But we urge you to do the best you can, and we want your support. I also want to commend the state and local health departments that have been so proactive.\n","I’m very proud of the way that -- that state has handled everything so far and has shown a willingness to work with us and our emergency management partners so that we can continue and keep expanding this response. We have about 80,000 people, from our first responders to the responders at the hospitals and health care facilities, now and we will be ramping up as we need more personnel and supplies. Some state and local health departments have already done an incredible job with their response.\n","Now, I would also like to add that in the states where there have been large-scale preparedness, the COVID-19 epidemic has affected many local and state health facilities, both hospitals and clinics, and I have a good sense of what is2: \n","<title=\"Government Response to the COVID-19 Pandemic\">\n","<speaker=\"Barack Obama\">\n","<year=\"1990\">\n","<summary=\"Hopsitals will need more personal protective equipment. The stock market is volatile. Everyone should adhere to social distancing and general hygiene to stay healthy.\">\n","<tone=\"analytical, joy\">\n","Health is personal -- it's personal. I grew up with my dad, who was a pharmacist and a cop and a fireman, and he had a very specific set of rules and regulations for his job that I didn't understand. Well he did, but he never mentioned them. I learned them from my father, but I learned them with him because I was only 10 years old. So today as a mom and an entrepreneur, I decided to start a company to change those regulations. And that is what happens to us here, folks. In short, it's up to all of us to find common ground, and we're going to do so with a new government agency called COVID-19.\n","This is a -- an unprecedented and dramatic outbreak. For this virus -- for this virus to spread is the result of -- from a combination of several factors that we know cause this kind of thing. And the first cause of the virus is the respiratory virus coronavirus, and there is no vaccine. Second cause of the virus is COVID-19 and respiratory syncytial virus, but there are no vaccines to treat the respiratory disease. Third cause of the virus is aerosolized human viruses -- a common indoor aerosol that is usually produced from air conditioning or air conditioners. And these viruses are spread throughout our city by a combination of the direct contact with infected aerosols, whether it's in restaurants or playgrounds, in the air that comes off of the city buildings -- and more so in the air that comes off the buildings from the airplanes and cars that are parked in the parking lot. And that's one cause of the virus. Now, we are seeing a third cause -- COVID-19 is also spreading from the air. For most of its incubation period, the virus was in the air, but for some time, COVID-19 was moving from the air into homes, shopping centers, and places of employment. And to the extent that we know the virus was in the air, it was then spread in the respiratory virus because it's a combination of two major diseases. So COVID-19 can affect someone who does\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ItJra6wG9-CD","colab_type":"text"},"source":["# Compute Perplexity\n","\n","We can use the transformers library to compute perplexity. Note that it might produce different scores from training if the block size is not set to the same value as the training phase."]},{"cell_type":"code","metadata":{"id":"DumK7_Nw8X-P","colab_type":"code","outputId":"a658ef11-5909-447f-befb-cb0536b16d27","executionInfo":{"status":"ok","timestamp":1590949871153,"user_tz":420,"elapsed":5798,"user":{"displayName":"Scott Bauersfeld","photoUrl":"","userId":"03921899941820663153"}},"colab":{"base_uri":"https://localhost:8080/","height":367}},"source":["!python run_language_modeling.py \\\n","    --output_dir=$OUTPUT_DIR_TRAIN \\\n","    --model_type=$MODEL_TYPE \\\n","    --model_name_or_path=$CHECKPOINT_PATH \\\n","    --do_eval \\\n","    --eval_data_file=$TRAIN_DATA_PATH \\\n","\n","print(\"Train data perplexity complete\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["2020-05-31 18:31:07.854495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/31/2020 18:31:09 - INFO - transformers.training_args -   PyTorch: setting up devices\n","05/31/2020 18:31:09 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/31/2020 18:31:09 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/content/gdrive/Shared drives/CS263/models/american_rhetoric/tones_watson-summarized_bart_large_xsm/converted-summary_tone/output_train', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir=None, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False)\n","Traceback (most recent call last):\n","  File \"run_language_modeling.py\", line 281, in <module>\n","    main()\n","  File \"run_language_modeling.py\", line 180, in main\n","    config = AutoConfig.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir)\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/configuration_auto.py\", line 197, in from_pretrained\n","    pretrained_model_name_or_path, pretrained_config_archive_map=ALL_PRETRAINED_CONFIG_ARCHIVE_MAP, **kwargs\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\", line 254, in get_config_dict\n","    config_dict = cls._dict_from_json_file(resolved_config_file)\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\", line 346, in _dict_from_json_file\n","    text = reader.read()\n","  File \"/usr/lib/python3.6/codecs.py\", line 318, in decode\n","    def decode(self, input, final=False):\n","KeyboardInterrupt\n","Train data perplexity complete\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5m7rMr_CExf7","colab_type":"code","outputId":"777464e8-060a-4541-e44e-32c75249a2b3","executionInfo":{"status":"ok","timestamp":1590949632141,"user_tz":420,"elapsed":2415,"user":{"displayName":"Scott Bauersfeld","photoUrl":"","userId":"03921899941820663153"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["!python run_language_modeling.py \\\n","    --output_dir=$OUTPUT_DIR_VAL \\\n","    --model_type=$MODEL_TYPE \\\n","    --model_name_or_path=$CHECKPOINT_PATH \\\n","    --do_eval \\\n","    --eval_data_file=$EVAL_DATA_PATH\n","\n","print(\"Eval data perplexity complete\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["python3: can't open file 'run_language_modeling.py': [Errno 2] No such file or directory\n","Eval data perplexity complete\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"II-V8Tb5EyOQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0087456d-3900-4db9-b5f6-949ca97c0e35","executionInfo":{"status":"ok","timestamp":1590950074658,"user_tz":420,"elapsed":182889,"user":{"displayName":"Scott Bauersfeld","photoUrl":"","userId":"03921899941820663153"}}},"source":["!python run_language_modeling.py \\\n","    --output_dir=$OUTPUT_DIR_TEST \\\n","    --model_type=$MODEL_TYPE \\\n","    --model_name_or_path=$MODEL_TYPE \\\n","    --do_eval \\\n","    --eval_data_file=$TEST_DATA_PATH \\\n","    --block_size 256\n","\n","print(\"Test data perplexity complete\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2020-05-31 18:31:34.293866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/31/2020 18:31:36 - INFO - transformers.training_args -   PyTorch: setting up devices\n","05/31/2020 18:31:36 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/31/2020 18:31:36 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/content/gdrive/Shared drives/CS263/models/american_rhetoric/tones_watson-summarized_bart_large_xsm/converted-summary_tone/output_test', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir=None, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False)\n","05/31/2020 18:31:36 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-config.json from cache at /root/.cache/torch/transformers/98aa65385e18b0efd17acd8bf64dcdf21406bb0c99c801c2d3c9f6bfd1f48f29.250d6dc755ccb17d19c7c1a7677636683aa35f0f6cb5461b3c0587bc091551a0\n","05/31/2020 18:31:36 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_layer\": 24,\n","  \"n_positions\": 1024,\n","  \"n_special\": 0,\n","  \"predict_special_tokens\": true,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","05/31/2020 18:31:37 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-config.json from cache at /root/.cache/torch/transformers/98aa65385e18b0efd17acd8bf64dcdf21406bb0c99c801c2d3c9f6bfd1f48f29.250d6dc755ccb17d19c7c1a7677636683aa35f0f6cb5461b3c0587bc091551a0\n","05/31/2020 18:31:37 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_layer\": 24,\n","  \"n_positions\": 1024,\n","  \"n_special\": 0,\n","  \"predict_special_tokens\": true,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","05/31/2020 18:31:37 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-vocab.json from cache at /root/.cache/torch/transformers/f20f05d3ae37c4e3cd56764d48e566ea5adeba153dcee6eb82a18822c9c731ec.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","05/31/2020 18:31:37 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-merges.txt from cache at /root/.cache/torch/transformers/6d882670c55563617571fe0c97df88626fb5033927b40fc18a8acf98dafd4946.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","05/31/2020 18:31:37 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-medium-pytorch_model.bin from cache at /root/.cache/torch/transformers/64652c50e84ddabb9bad81a37ff82624ab70053f402f8d9a58c0e90fb8289fb6.8769029be4f66a5ae1055eefdd1d11621b901d510654266b8681719fff492d6e\n","05/31/2020 18:31:52 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","05/31/2020 18:31:52 - INFO - filelock -   Lock 140109658747344 acquired on /content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone/cached_lm_GPT2Tokenizer_256_data-test.txt.lock\n","05/31/2020 18:31:53 - INFO - transformers.data.datasets.language_modeling -   Loading features from cached file /content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone/cached_lm_GPT2Tokenizer_256_data-test.txt [took 0.721 s]\n","05/31/2020 18:31:53 - INFO - filelock -   Lock 140109658747344 released on /content/gdrive/Shared drives/CS263/data/american_rhetoric/speech_bank/tones_watson-summarized_bart_large_xsm/converted-summary_tone/cached_lm_GPT2Tokenizer_256_data-test.txt.lock\n","05/31/2020 18:31:56 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n","05/31/2020 18:31:56 - INFO - __main__ -   *** Evaluate ***\n","05/31/2020 18:31:56 - INFO - transformers.trainer -   ***** Running Evaluation *****\n","05/31/2020 18:31:56 - INFO - transformers.trainer -     Num examples = 1314\n","05/31/2020 18:31:56 - INFO - transformers.trainer -     Batch size = 8\n","Evaluation: 100% 165/165 [02:32<00:00,  1.09it/s]\n","{\"eval_loss\": 3.1141098600445374, \"step\": null}\n","05/31/2020 18:34:28 - INFO - __main__ -   ***** Eval results *****\n","05/31/2020 18:34:28 - INFO - __main__ -     perplexity = 22.513381371327227\n","Test data perplexity complete\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q3DCoNrW-Q88","colab_type":"text"},"source":["We also have a custom script for computing perplexity, but it is likely less accurate than the transformers library."]},{"cell_type":"code","metadata":{"id":"bh5eUDOu6s_t","colab_type":"code","outputId":"a7c06776-ae56-49c7-a2a5-dac7bfef0389","executionInfo":{"status":"error","timestamp":1590364441509,"user_tz":420,"elapsed":56307,"user":{"displayName":"Rahul Malavalli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbifDzHTnML8VT4EdmdRi-HUErISJBI-JgIuXntg=s64","userId":"03380049511998254325"}},"colab":{"base_uri":"https://localhost:8080/","height":416}},"source":["import torch\n","import math\n","import numpy as np\n","\n","SPEECH_LIMIT=100 # limit number of speeches to use to reduce computation time\n","\n","def split_speech_by_sentence(speech):\n","  length_limit = 100\n","  sentences = []\n","  sent = \"\"\n","  for char in speech:\n","    if char == \".\" and len(sent) > length_limit:\n","      sentences.append(sent)\n","      sent = \"\"\n","    else:\n","      sent += char\n","\n","  if sent != \"\" and len(sent) > length_limit:\n","    sentences.append(sent)\n","\n","  return sentences\n","\n","def score_speech(model, tokenizer, speech):\n","    sentences = split_speech_by_sentence(speech)\n","\n","    loss = 0.0\n","    with torch.no_grad():\n","      for sent in sentences:\n","        tensor_input = tokenizer.encode(sent, return_tensors=\"pt\").unsqueeze(0).to(device)\n","        loss += model(tensor_input, labels=tensor_input)[0].item() * len(sent)\n","    return loss\n","\n","def get_perplexity(speech_limit, model, tokenizer, filepath):\n","  speech = \"\"\n","  total_loss = 0.0\n","  num_speeches = 0\n","  num_words = 0\n","  with open(filepath) as fp:\n","    for line in fp:\n","      if \"<title=\" in line and speech != \"\":\n","        total_loss += score_speech(model, tokenizer, speech)\n","        num_words += len(speech)\n","        speech = line\n","        num_speeches += 1\n","        if speech_limit is not None and num_speeches >= speech_limit:\n","          speech = \"\"\n","          break\n","      else:\n","        speech += line\n","    \n","    if speech != \"\":\n","      total_loss += score_speech(model, tokenizer, speech)\n","      num_speeches += 1\n","\n","    print(\"Number of speeches in dataset:\", num_speeches)\n","    return math.exp(total_loss / num_words)\n","\n","train_perplexity = get_perplexity(SPEECH_LIMIT, model, tokenizer, TRAIN_DATA)\n","print(\"Train perplexity is:\", train_perplexity)\n","\n","eval_perplexity = get_perplexity(SPEECH_LIMIT, model, tokenizer, EVAL_DATA)\n","print(\"Eval perplexity is:\", eval_perplexity)\n","\n","test_perplexity = get_perplexity(SPEECH_LIMIT, model, tokenizer, TEST_DATA)\n","print(\"Test perplexity is:\", test_perplexity)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-2789284e864f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mtrain_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSPEECH_LIMIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train perplexity is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_perplexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-2789284e864f>\u001b[0m in \u001b[0;36mget_perplexity\u001b[0;34m(speech_limit, model, tokenizer, filepath)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"<title=\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mspeech\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mscore_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeech\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mnum_words\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mspeech\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-2789284e864f>\u001b[0m in \u001b[0;36mscore_speech\u001b[0;34m(model, tokenizer, speech)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtensor_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         )\n\u001b[1;32m    617\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache)\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                 \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m             )\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, layer_past, attention_mask, head_mask, use_cache)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_attn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, layer_past, attention_mask, head_mask, use_cache)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mattn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, q, k, v, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnd\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1024) must match the size of tensor b (1415) at non-singleton dimension 3"]}]}]}